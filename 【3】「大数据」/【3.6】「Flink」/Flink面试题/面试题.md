



## 1:压测和监控

```
🉑️：怎么做压力测试和监控？

一、产生数据流的速度如果够快，而下游的算子消费不过来，会产生背压。
		背压的监控可以使用Flink Web UI来可视化监控，一旦报警就能知道。
		一般情况下背压问题是由于sink的操作没有优化好，比如改成批量写入。

二、设置watermark的最大延迟时间，如果设置的过大，可能会造成内存的压力。
		可以设置最大延迟时间小一些，然后把迟到元素发送到侧输出流中去。晚一点更新结果。

三、滑动窗口的长度如果过长，而滑动距离很短的话，Flink的性能会下降的很厉害。
		我们主要通过事件分片的芳华，将每个元素只存一个“重叠窗口”，这样就可以减少窗口处理中状态的写入。
```



## 2: 为什么用Flink

```
🉑️：为什么用Flink替代Spark？

主要考虑的是Flink的第延迟、高吞吐和对流式数据应用场景更好的支持；另外，flink可以很好的处理乱序数据，而且可以保证exactly-once的状态一致性。

支持低延时、高吞吐、高性能的流处理
支持带有事件时间的窗口操作
支持有状态计算的exactly-once语义
支持高度灵活的窗口操作，
支持基于time、count、session以及data-driven的窗口操作
支持基于轻量级分布式快照实现的容错一个运行

```



## 3：checkpoint的存储

```
🉑️：Flink的checkpoint存在哪里

内存或者是文件系统
MemoryStateBackend
内存级的状态后端，会将键控状态作为内存中的对象进行管理，将他们存储在TaskManager的JVM堆上；而将checkpoint存储在JobManager的内存中。
FsStateBackend

```



## 4: exactly-once的保证

```
🉑️：如果下级存储不支持事务，Flink如何保证exactly-once？

端到端的exactly-once对sink要求比较高，具体实现主要有幂等写入和事物写入两种方式。
幂等写入的场景依赖于业务逻辑，更常见的是事务性写入。
而事务性写入又有预写日志和两阶段提交两种方式。
如果外部系统不支持事务，那么可以用预写日志的方式，把结果数据先当成状态保存，然后在收到checkpoint完成的通知时，一次性写入sink系统。


🉑️：checkpoint机制

它采用的是轻量级的分布式快照，实现了每个算子的快照，及流动中的数据的快照

```



## 5:状态机制

```
🉑️：什么是状态机制？

Flink内置的很多算子，包括source，数据存储的sink都是有状态的。在Flink中，状态始终与特定的算子相关联。Flink会以checkpoint的形式对各个任务的状态进行快照，用于保证故障恢复时的状态一致性。Flink通过状态后端来管理状态和checkpoint的存储，状态后端可以有不同的配置选择。

🉑️：Flink中的状态存储？
Flink在做计算的过程中经常需要存储中间状态，来避免数据丢失和状态恢复。选择的状态存储策略不同，会影响状态持久化如何和checkpoint交互。Flink提供了三种状态存储方式：MemoryStateBackend、FsStateBackend、RocksDBStateBackend


```



## 6: watermark机制

```
🉑️：Flink的Watermark机制

watermaek的本质是Flink中事件事件时间的一个机制，主要用来处理乱序数据
通过watermark机制来处理乱序的问题，属于第一层防护，属于全局性的防护，通常说的乱序问题的解决办法。
通过窗口上的allowedLateness机制来处理out-of-order的问题，属于第二层防护，属于特定window operator的防护。
```



## 7: 三种时间语义

```
1、事件时间
2、处理时间
3、摄入时间
```



## 8: 数据高峰的处理

```
🉑️： Flink程序在面对数据高峰期时如何处理？

使用大容量的Kafka把数据先放到消息队列里面作为数据源，在使用Flink进行消费，不过这样会影响数据的实时性。
```



## 9: 容错机制

```
🉑️：Flink是如何做容错的？

Flink实现容错主要靠强大的Checkpoint机制和State机制。Checkpoint负责定时制作分布式快照、对程序中的状态进行备份；State用来存储计算过程的中间状态。
```



## 10:Flink重启策略

```
固定延迟重启策略（Fixed Delay Restart Strategy）

故障率重启策略（Failure Rate Restart Strategy）

没有重启策略（No Restart Strategy）

Fallback重启策略（Fallback Restart Strategy）
```



## 11:数据倾斜

```
2⃣️数据源 source 消费不均匀 
	- 通过调整并发度，解决数据源消费不均匀或者数据源反压的情况。例如kafka数据源，可以调整 KafkaSource 的并发度解决消费不均匀。调整并发度的原则：KafkaSource 并发度与 kafka 分区数是一样的，或者 kafka 分区数是KafkaSource 并发度的整数倍。
	- 在我们接收到 Kafka 消息后，可以通过自定义数据分区策略来实现数据的负载均衡.其中，Rebalance 分区策略，数据会以 round-robin 的方式对数据进行再次分区，可以全局负载均衡。Rescale 分区策略基于上下游的并行度，会将数据以循环的方式输出到下游的每个实例中。
3⃣️key分布不均匀的无统计场景，例如上游数据分布不均匀，使用keyBy来打散数据。
	- 通过添加随机前缀，打散 key 的分布，使得数据不会集中在几个 Subtask。
4⃣️key分布不均匀的统计场景
	- 聚合统计前，先进行预聚合，例如两阶段聚合（加盐局部聚合+去盐全局聚合）。
1⃣️的是数据在不同的窗口内堆积的数据量相差过多。本质上产生这种情况的原因是数据源头发送的数据量速度不同导致的。出现这种情况一般通过两种方式来解决：
	- 在数据进入窗口前做预聚合
	- 重新设计窗口聚合的key
```



## 反压

```
🉑️Flink任务延迟高

在Flink的后台任务管理中，我们可以看到Flink的哪个算子和task出现了反压。最主要的手段是资源调优和算子调优。资源调优即是对作业中的Operator的并发数（parallelism）、CPU（core）、堆内存（heap_memory）等参数进行调优。作业参数调优包括：并行度的设置，State的设置，checkpoint的设置。

🉑️Flink是如何处理反压的？

Flink 内部是基于 producer-consumer 模型来进行消息传递的，Flink的反压设计也是基于这个模型。Flink 使用了高效有界的分布式阻塞队列，就像 Java 通用的阻塞队列（BlockingQueue）一样。下游消费者消费变慢，上游就会受到阻塞。



```



## 算子链

```
🉑️ 算子链
Flink会尽可能地将operator的subtask链接（chain）在一起形成task。每个task在一个线程中执行。
它能减少线程之间的切换，
减少消息的序列化/反序列化，
减少数据在缓冲区的交换，
减少了延迟的同时提高整体的吞吐量。
```



## 消费kafka数据的时候，如何处理脏数据？

```
可以在处理前加一个fliter算子，将不符合规则的数据过滤出去。
```



## Task Slot 进行资源管理

```
TaskManager是实际负责执行计算的
TaskManager是一个JVM 进程，并会以独立的线程来执行一个task或多个subtask
为了控制一个 TaskManager 能接受多少个 task，Flink 提出了 Task Slot 的概念

简单的说，TaskManager 会将自己节点上管理的资源分为不同的 Slot：固定大小的资源子集。这样就避免了不同 Job 的 Task 互相竞争内存资源，但是需要主要的是，Slot 只会做内存的隔离。没有做 CPU 的隔离。

```



## Flink并行度

```
算子层面>环境层面>客户端层面>系统层面。
```

![截屏2021-10-07 上午11.08.55](/Users/peiyang/Library/Application Support/typora-user-images/截屏2021-10-07 上午11.08.55.png)

## Flink海量数据高效去重

```
①基于状态后端
②基于HyperLogLog：不是精准的去重
③基于布隆过滤器（BloomFilter）
快速判断一个key是否存在于某容器，不存在就直接返回。
④基于BitMap
用一个bit位来标记某个元素对应的Value，而Key即是该元素。由于采用了Bit为单位来存储数据，因此可以大大节省存储空间。
⑤基于外部数据库
选择使用Redis或者HBase存储数据，我们只需要设计好存储的Key即可，不需要关心Flink任务重启造成的状态丢失问题
```



所有的 java 程序会首先被编译为.class 的类文件，这种类文件可以在虚拟机上执行，也就是说 class 并不直接与机器的操作系统相对应，而是经过虚拟机间接与操作系统交互，由虚拟机将程序解释给本地系统执行

多线程是为了同步完成多项[任务](https://baike.baidu.com/item/任务)，不是为了提高运行效率，而是为了提高[资源](https://baike.baidu.com/item/资源)使用效率来提高系统的效率。线程是在同一时间需要完成多项[任务](https://baike.baidu.com/item/任务)的时候实现的

多线程就是把操作系统中的这种并发执行机制原理运用在一个程序中，把一个程序划分为若干个子任务，多个子任务并发执行，每一个任务就是一个线程。这就是多线程程序
