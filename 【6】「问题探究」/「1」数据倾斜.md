```shell
# 数据倾斜
数据倾斜在MapReduce计算框架中经常发生。通俗理解，该现象指的是在整个计算过程中，大量相同的key被分配到了同一个任务上，造成“一个人累死、其他人闲死”的状况，这违背了分布式计算的初衷，使得整体的执行效率十分低下。
```



```shell
# 数据倾斜定位与出现问题的位置：

出现数据倾斜的原因，基本只可能是因为发生了shuffle操作，在shuffle的过程中，出现了数据倾斜的问题。因为某个，或者某些key对应的数据，远远的高于其他的key。
1、你在自己的程序里面找找，哪些地方用了会产生shuffle的算子，groupByKey、countByKey、reduceByKey、join

2、log一般会报是在你的哪一行代码，导致了OOM异常；或者呢，看log，看看是执行到了第几个stage！！！哪一个stage，task特别慢，就能够自己用肉眼去对你的spark代码进行stage的划分，就能够通过stage定位到你的代码，哪里发生了数据倾斜。去找找，代码那个地方，是哪个shuffle操作。

```



```shell
# 处理

场景一：数据源 source 消费不均匀 
解决思路：通过调整并发度，解决数据源消费不均匀或者数据源反压的情况。例如kafka数据源，可以调整 KafkaSource 的并发度解决消费不均匀。调整并发度的原则：KafkaSource 并发度与 kafka 分区数是一样的，或者 kafka 分区数是KafkaSource 并发度的整数倍。

在我们接收到 Kafka 消息后，可以通过自定义数据分区策略来实现数据的负载均衡.其中，Rebalance 分区策略，数据会以 round-robin 的方式对数据进行再次分区，可以全局负载均衡。Rescale 分区策略基于上下游的并行度，会将数据以循环的方式输出到下游的每个实例中

dataStream
        .setParallelism(2)
        // 采用REBALANCE分区策略重分区
        .rebalance() //.rescale()
        .print()
        .setParallelism(4);


场景二：key 分布不均匀的无统计场景
说明：key 分布不均匀的无统计场景，例如上游数据分布不均匀，使用keyBy来打散数据。
解决思路： 通过添加随机前缀，打散 key 的分布，使得数据不会集中在几个 Subtask。


场景三：key 分布不均匀的统计场景
解决思路：聚合统计前，先进行预聚合，例如两阶段聚合（加盐局部聚合+去盐全局聚合）。
```

![截屏2021-09-11 下午8.48.01](/Users/peiyang/Library/Application Support/typora-user-images/截屏2021-09-11 下午8.48.01.png)





```
# 8种重分区策略
GlobalPartitioner
ShufflePartitioner
RebalancePartitioner
RescalePartitioner
BroadcastPartitioner
ForwardPartitioner
KeyGroupStreamPartitioner
CustomPartitionerWrapper
```









